{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import csv\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "\n",
    "Material = \"Material E\"\n",
    "\n",
    "#%% Calculate Core Loss\n",
    "def core_loss(data_B, data_F, data_T):\n",
    "    \n",
    "    DataF1 = data_F\n",
    "    DataB1 = data_B\n",
    "    DataT1 = data_T \n",
    "    %run MasterCode_DataSplit2.ipynb \n",
    "\n",
    "    print('\\nPerforming triangular data testing')     \n",
    "    %run Trig_Tests.ipynb\n",
    "\n",
    "    print('\\nPerforming sinusoidal data testing')\n",
    "    %run Sine_Tests.ipynb\n",
    "\n",
    "    print('\\nPerforming trapezoidal data testing')\n",
    "    %run Trap_Tests.ipynb\n",
    "\n",
    "    Ploss = np.concatenate((sine_test_out,trig_test_out,trap_test_out), axis=0)\n",
    "    Ind = np.concatenate((sine_index,trig_index,trap_index), axis=0)\n",
    "\n",
    "    df = pd.concat([pd.DataFrame(Ploss), pd.DataFrame(Ind)], ignore_index=True, axis=1)\n",
    "    data = df.sort_values(by=1) \n",
    "    data_P = data[0].to_numpy()\n",
    "    data_Ind = data[1].to_numpy()\n",
    "\n",
    "    for i in range(0,len(data_F)):\n",
    "        if (data_Ind[i]!=(i+1)):\n",
    "            data_Ind = np.insert(data_Ind,i,i+1)\n",
    "            data_P = np.insert(data_P,i,0)\n",
    "\n",
    "    f1 = './IISc/Result/Volumetric_Loss_'+Material+'.xlsx'\n",
    "\n",
    "    workbook = xlsxwriter.Workbook(f1)\n",
    "    worksheet = workbook.add_worksheet('Data')\n",
    "    row = 0 \n",
    "    for kk in range (0,len(data_P)):\n",
    "        worksheet.write(row,0,data_P[kk])\n",
    "        row +=1\n",
    "    workbook.close()\n",
    "\n",
    "    print('Model inference is finished!')\n",
    "    \n",
    "    return\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    dataB = pd.read_csv('./Testing/'+ Material+'/B_Field.csv',header=None)\n",
    "    dataF = pd.read_csv('./Testing/'+ Material+'/Frequency.csv',header=None)\n",
    "    dataT = pd.read_csv('./Testing/'+ Material+'/Temperature.csv',header=None)\n",
    "\n",
    "    data_B = dataB.to_numpy()\n",
    "    data_F = dataF.to_numpy()\n",
    "    data_T = dataT.to_numpy()\n",
    "\n",
    "    # Reproducibility\n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "    core_loss(data_B, data_F, data_T)\n",
    "    \n",
    "# # End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
