{"cells":[{"cell_type":"markdown","metadata":{"id":"XQSzNovNpM1J"},"source":["# User Colab Path Setting"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"BY47VVFEpe5q","executionInfo":{"status":"ok","timestamp":1703108180270,"user_tz":0,"elapsed":193,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"}}},"outputs":[],"source":["colab_dir = '/content/drive/MyDrive/DeepLearning/Challange_comb_shift_flip/MagNet_comb_modelC_cycle'  # example for colab\n","\n","platform = 'auto' # auto detect platform (colab, windows_local, linux_local, unknown)\n","#platform = 'colab'\n","#platform = 'windows_local'\n","#platform = 'linux_local'\n","#platform = 'unknown'"]},{"cell_type":"markdown","metadata":{"id":"EN1rAR3ADcfK"},"source":["# Trainnig process"]},{"cell_type":"markdown","metadata":{"id":"Ey9byKn_DcfK"},"source":["### Defult path config"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"F5fy2h1NDcfK","executionInfo":{"status":"ok","timestamp":1703108180448,"user_tz":0,"elapsed":3,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"}}},"outputs":[],"source":["model_saved_name=\"model_tl.ckpt\"\n","dataset_path=\"data/tl_dataset\""]},{"cell_type":"markdown","metadata":{"id":"F3jSpmi4pU5n"},"source":["### Path config"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1474,"status":"ok","timestamp":1703108181919,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"7EAuEhFiocKq","outputId":"1aca1d58-5df7-4af2-b0ab-65023753f4df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","current execution path:  /content/drive/MyDrive/DeepLearning/Challange_comb_shift_flip/MagNet_comb_modelC_cycle\n","\n","current platform:  colab\n"]}],"source":["import os\n","\n","try:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","except ImportError:\n","    if os.path.exists('c:/'):  # check if it is windows\n","        platform = 'windows_local'\n","    elif os.path.exists('/home/'):  # check if it is linux\n","        platform = 'linux_local'\n","    else:\n","        platform = 'unknown'\n","else:\n","    platform = 'colab'\n","\n","if platform == 'colab':\n","  os.chdir(colab_dir)\n","\n","print('\\ncurrent execution path: ', os.getcwd())  #获取当前工作目录路径\n","print('\\ncurrent platform: ', platform)  #获取当前工作目录路径"]},{"cell_type":"markdown","metadata":{"id":"CHDhat43ogMQ"},"source":["## Cuda check"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1703108181919,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"7Aipe8RLOzQk","outputId":"fec4ecdf-ea80-462e-dc1a-3732b31dab82"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda good!\n","GPU num:  1\n","GPU type:  Tesla V100-SXM2-16GB\n","GPU memory: 16.94 Gbyte\n"]}],"source":["import torch\n","\n","gpu_num = 0\n","cuda_ready = False\n","\n","if torch.cuda.is_available():\n","    cuda_ready = True\n","    print('cuda good!')\n","    gpu_num = torch.cuda.device_count()\n","    if (gpu_num < 1):\n","        print('GPU unavailable')\n","    else:\n","        print('GPU num: ', gpu_num)  # 查看GPU数量\n","        for gpu in range(gpu_num):\n","            print('GPU type: ', torch.cuda.get_device_name(gpu))  # 查看GPU名称\n","            print('GPU memory: {:.2f} Gbyte'.format(\n","                torch.cuda.get_device_properties(gpu).total_memory /\n","                1e9))  # 查看GPU总内存\n","else:\n","    cuda_ready = False\n","    print('cuda unavailable!')\n"]},{"cell_type":"markdown","metadata":{"id":"9z1whOUtaPbq"},"source":["## Start coding"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1703108181920,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"LSndganfafmO","outputId":"082cd8a8-0454-4ad9-ffb7-9e8d88c200c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["colab\n","/content/drive/MyDrive/DeepLearning/Challange_comb_shift_flip/MagNet_comb_modelC_cycle\n","True\n","/content/drive/MyDrive/DeepLearning/Challange_comb_shift_flip/MagNet_comb_modelC_cycle\n"]}],"source":["print(platform)\n","print(os.getcwd())\n","print(cuda_ready)\n","print(os.path.abspath(''))"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"8q3WkMaUtvSZ","executionInfo":{"status":"ok","timestamp":1703108181920,"user_tz":0,"elapsed":6,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","\n","\n","import NW_LSTM\n","import NN_DataLoader"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1703108181920,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"ftzXEac3tyHc","outputId":"dd5ef9dd-37ba-47c9-a231-63c99da5560e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device using  cuda\n","LSTMSeq2One(\n","  (lstm): LSTM(1, 30, num_layers=3, batch_first=True)\n","  (fc1): Linear(in_features=32, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=196, bias=True)\n","  (fc3): Linear(in_features=196, out_features=128, bias=True)\n","  (fc4): Linear(in_features=128, out_features=96, bias=True)\n","  (fc5): Linear(in_features=96, out_features=32, bias=True)\n","  (fc6): Linear(in_features=32, out_features=32, bias=True)\n","  (fc7): Linear(in_features=32, out_features=16, bias=True)\n","  (fc8): Linear(in_features=16, out_features=1, bias=True)\n","  (relu): ReLU()\n","  (leaky_relu): LeakyReLU(negative_slope=0.01)\n","  (elu): ELU(alpha=1.0)\n","  (sigmoid): Sigmoid()\n",")\n","Total number of parameters:  90653\n","Pre-train model loaded\n"]}],"source":["# Check if CUDA is available and if so, set the device to GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#device = torch.device(\"cpu\")\n","print(\"Device using \",device)\n","\n","# Instantiate the model with appropriate dimensions\n","model = model = NW_LSTM.get_global_model().to(device)\n","\n","# Print the model architecture and parameters number\n","print(model)\n","print(\"Total number of parameters: \", sum(p.numel() for p in model.parameters()))\n","\n","# Load the pre-train model if it exists\n","try:\n","    model.load_state_dict(torch.load(model_saved_name))\n","    print(\"Pre-train model loaded\")\n","except:\n","    print(\"No model found, start training from scratch\")\n","    pass\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QKhTKu9cDcfN"},"source":["### Define training para"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"X6OqVZExt06B","executionInfo":{"status":"ok","timestamp":1703108181920,"user_tz":0,"elapsed":5,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"}}},"outputs":[],"source":["def train_model(epoch_num=700,lr=2e-4,method=\"forward\"):\n","\n","    # Define the loss function and optimizer\n","    #loss_fn = nn.MSELoss()\n","    loss_fn = NW_LSTM.RelativeLoss()\n","    #loss_fn = NW_LSTM.RelativeLoss_abs()\n","    optimizer = optim.AdamW(model.parameters(), lr=lr)\n","\n","    # lr scheduler\n","    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=1, last_epoch=-1)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200, eta_min=0, last_epoch=-1)\n","\n","    # Default para in desktop env\n","    epochs = 10\n","    valid_batch_size=1000\n","\n","    if platform == \"colab\":\n","      epochs = epoch_num\n","      valid_batch_size=3000\n","\n","\n","    train_dataloader = NN_DataLoader.get_dataLoader(os.path.normpath(dataset_path +\n","                                                                \"/train.mat\"),\n","                                            batch_size=128)\n","\n","    # Get validation data\n","    valid_dataloader = NN_DataLoader.get_dataLoader(os.path.normpath(dataset_path +\n","                                                                \"/valid.mat\"),\n","                                                batch_size=valid_batch_size)\n","    valid_inputs, valid_targets = next(iter(valid_dataloader))\n","    valid_inputs, valid_targets = valid_inputs.to(device), valid_targets.to(device)\n","\n","\n","\n","    # estimate time used for training\n","    import time\n","    t0 = time.perf_counter()\n","\n","    # Save the model with the lowest validation loss\n","    with torch.no_grad():\n","        valid_outputs = model(valid_inputs)\n","        # Compute loss\n","        minium_loss = loss_fn(valid_outputs, valid_targets)\n","\n","    # Train the model\n","    for epoch in range(epochs):\n","\n","\n","        # estimate time used for one epoch(s)\n","        t_epoch = time.perf_counter() - t0\n","        t0 = time.perf_counter()\n","\n","        # Train one epoch\n","        for i, (train_inputs, train_targets) in enumerate(train_dataloader):\n","            # Move data to device\n","            train_inputs, train_targets = train_inputs.to(device), train_targets.to(device)\n","\n","            # Forward pass\n","            if method == \"forward\":\n","                train_outputs = model(train_inputs)\n","            elif method == \"valid\":\n","                train_outputs = model.valid(train_inputs)\n","\n","            # Compute loss\n","            loss = loss_fn(train_outputs, train_targets)\n","\n","            # Backward pass and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Compute validation loss\n","        if epoch > 0:\n","            with torch.no_grad():\n","                valid_outputs = model(valid_inputs)\n","                # Compute loss\n","                valid_loss = loss_fn(valid_outputs, valid_targets)\n","\n","            if valid_loss < minium_loss:\n","                minium_loss = valid_loss\n","                torch.save(model.state_dict(), model_saved_name)\n","                print(f\"  Model saved , Validation Loss: {valid_loss.item():.3e}, lr: {optimizer.param_groups[0]['lr']:.3e}\")\n","\n","        # update lr\n","        scheduler.step()\n","\n","        # Print loss every 10 epochs\n","        if (epoch + 1) % 10 == 0:\n","            print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {loss.item():.3e}, \"\n","                #   f\"Validation Loss: {valid_loss.item():.3e} ,\"\n","                f\"Remain time: {t_epoch/60 * (epochs - epoch - 1):.1f} min\")\n"]},{"cell_type":"markdown","metadata":{"id":"JVWF5osJDcfN"},"source":["### Training loop"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"HVfNZrtoottv","executionInfo":{"status":"ok","timestamp":1703108181920,"user_tz":0,"elapsed":4,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"}}},"outputs":[],"source":["#train_model(epoch_num=10,lr=2e-4,method=\"forward\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":986958,"status":"error","timestamp":1703109168874,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"oGiB5uWYottv","outputId":"60a20411-2fd0-4867-f381-754242c29943"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 10/1300, Training Loss: 1.986e-03, Remain time: 15.2 min\n","Epoch 20/1300, Training Loss: 3.129e-03, Remain time: 21.3 min\n","Epoch 30/1300, Training Loss: 4.724e-02, Remain time: 15.1 min\n","Epoch 40/1300, Training Loss: 1.798e-02, Remain time: 15.0 min\n","Epoch 50/1300, Training Loss: 1.037e-02, Remain time: 14.7 min\n","Epoch 60/1300, Training Loss: 4.770e-03, Remain time: 15.4 min\n","Epoch 70/1300, Training Loss: 4.144e-03, Remain time: 15.3 min\n","Epoch 80/1300, Training Loss: 4.729e-03, Remain time: 14.5 min\n","Epoch 90/1300, Training Loss: 5.355e-03, Remain time: 20.6 min\n","Epoch 100/1300, Training Loss: 4.407e-03, Remain time: 14.1 min\n","Epoch 110/1300, Training Loss: 5.480e-03, Remain time: 20.0 min\n","Epoch 120/1300, Training Loss: 6.167e-03, Remain time: 14.0 min\n","Epoch 130/1300, Training Loss: 3.489e-03, Remain time: 18.1 min\n","Epoch 140/1300, Training Loss: 4.832e-03, Remain time: 13.9 min\n","Epoch 150/1300, Training Loss: 2.817e-03, Remain time: 13.3 min\n","Epoch 160/1300, Training Loss: 1.955e-03, Remain time: 19.5 min\n","Epoch 170/1300, Training Loss: 3.130e-03, Remain time: 13.5 min\n","Epoch 180/1300, Training Loss: 2.724e-03, Remain time: 18.9 min\n","Epoch 190/1300, Training Loss: 2.291e-03, Remain time: 13.3 min\n","Epoch 200/1300, Training Loss: 1.284e-03, Remain time: 19.1 min\n","Epoch 210/1300, Training Loss: 3.053e-03, Remain time: 12.8 min\n","Epoch 220/1300, Training Loss: 2.769e-03, Remain time: 16.1 min\n","Epoch 230/1300, Training Loss: 1.979e-03, Remain time: 12.7 min\n","Epoch 240/1300, Training Loss: 3.484e-03, Remain time: 12.7 min\n","Epoch 250/1300, Training Loss: 3.200e-03, Remain time: 12.5 min\n","Epoch 260/1300, Training Loss: 1.504e-03, Remain time: 12.3 min\n","Epoch 270/1300, Training Loss: 1.817e-03, Remain time: 12.4 min\n","Epoch 280/1300, Training Loss: 3.380e-03, Remain time: 12.5 min\n","Epoch 290/1300, Training Loss: 4.070e-03, Remain time: 17.4 min\n","Epoch 300/1300, Training Loss: 1.446e-03, Remain time: 11.9 min\n","Epoch 310/1300, Training Loss: 2.767e-03, Remain time: 16.7 min\n","Epoch 320/1300, Training Loss: 5.732e-03, Remain time: 11.6 min\n","Epoch 330/1300, Training Loss: 3.795e-03, Remain time: 11.7 min\n","Epoch 340/1300, Training Loss: 1.715e-03, Remain time: 11.1 min\n","Epoch 350/1300, Training Loss: 2.465e-03, Remain time: 11.1 min\n","Epoch 360/1300, Training Loss: 7.226e-03, Remain time: 10.9 min\n","Epoch 370/1300, Training Loss: 2.980e-03, Remain time: 11.9 min\n","Epoch 380/1300, Training Loss: 2.240e-03, Remain time: 14.2 min\n","Epoch 390/1300, Training Loss: 6.108e-03, Remain time: 10.7 min\n","Epoch 400/1300, Training Loss: 3.522e-02, Remain time: 15.7 min\n","Epoch 410/1300, Training Loss: 3.040e-03, Remain time: 10.3 min\n","Epoch 420/1300, Training Loss: 1.710e-03, Remain time: 15.6 min\n","Epoch 430/1300, Training Loss: 2.737e-03, Remain time: 10.2 min\n","Epoch 440/1300, Training Loss: 2.075e-02, Remain time: 10.2 min\n","Epoch 450/1300, Training Loss: 1.010e-03, Remain time: 10.3 min\n","Epoch 460/1300, Training Loss: 1.121e-03, Remain time: 10.1 min\n","Epoch 470/1300, Training Loss: 1.210e-03, Remain time: 9.9 min\n","Epoch 480/1300, Training Loss: 1.729e-03, Remain time: 9.6 min\n","Epoch 490/1300, Training Loss: 2.049e-03, Remain time: 13.8 min\n","Epoch 500/1300, Training Loss: 5.617e-04, Remain time: 9.5 min\n","Epoch 510/1300, Training Loss: 1.445e-03, Remain time: 13.5 min\n","Epoch 520/1300, Training Loss: 9.279e-04, Remain time: 9.1 min\n","Epoch 530/1300, Training Loss: 1.008e-03, Remain time: 12.9 min\n","Epoch 540/1300, Training Loss: 1.935e-03, Remain time: 9.0 min\n","Epoch 550/1300, Training Loss: 1.310e-03, Remain time: 8.9 min\n","Epoch 560/1300, Training Loss: 9.589e-04, Remain time: 8.8 min\n","Epoch 570/1300, Training Loss: 9.576e-04, Remain time: 8.8 min\n","Epoch 580/1300, Training Loss: 6.725e-04, Remain time: 8.5 min\n","Epoch 590/1300, Training Loss: 5.687e-04, Remain time: 8.5 min\n","Epoch 600/1300, Training Loss: 1.199e-03, Remain time: 11.6 min\n","Epoch 610/1300, Training Loss: 8.060e-04, Remain time: 8.1 min\n","Epoch 620/1300, Training Loss: 6.943e-04, Remain time: 14.7 min\n","Epoch 630/1300, Training Loss: 1.022e-03, Remain time: 7.9 min\n","Epoch 640/1300, Training Loss: 9.032e-04, Remain time: 11.0 min\n","Epoch 650/1300, Training Loss: 8.670e-04, Remain time: 7.8 min\n","Epoch 660/1300, Training Loss: 1.062e-03, Remain time: 7.6 min\n","Epoch 670/1300, Training Loss: 3.922e-03, Remain time: 7.5 min\n","Epoch 680/1300, Training Loss: 4.476e-03, Remain time: 7.3 min\n","Epoch 690/1300, Training Loss: 2.409e-03, Remain time: 7.7 min\n","Epoch 700/1300, Training Loss: 8.935e-04, Remain time: 7.0 min\n","Epoch 710/1300, Training Loss: 1.419e-03, Remain time: 9.3 min\n","Epoch 720/1300, Training Loss: 8.199e-04, Remain time: 6.9 min\n","Epoch 730/1300, Training Loss: 1.704e-03, Remain time: 9.7 min\n","Epoch 740/1300, Training Loss: 6.311e-02, Remain time: 6.6 min\n","Epoch 750/1300, Training Loss: 8.512e-04, Remain time: 9.8 min\n","Epoch 760/1300, Training Loss: 9.825e-04, Remain time: 6.6 min\n","Epoch 770/1300, Training Loss: 9.074e-04, Remain time: 6.4 min\n","Epoch 780/1300, Training Loss: 1.363e-03, Remain time: 6.2 min\n","Epoch 790/1300, Training Loss: 8.001e-03, Remain time: 6.0 min\n","Epoch 800/1300, Training Loss: 1.450e-03, Remain time: 5.9 min\n","Epoch 810/1300, Training Loss: 9.161e-04, Remain time: 5.9 min\n","Epoch 820/1300, Training Loss: 1.847e-03, Remain time: 8.1 min\n","Epoch 830/1300, Training Loss: 5.810e-03, Remain time: 5.6 min\n","Epoch 840/1300, Training Loss: 3.220e-03, Remain time: 7.9 min\n","Epoch 850/1300, Training Loss: 2.343e-03, Remain time: 5.2 min\n","Epoch 860/1300, Training Loss: 1.566e-03, Remain time: 5.8 min\n","Epoch 870/1300, Training Loss: 1.140e-03, Remain time: 5.1 min\n","Epoch 880/1300, Training Loss: 1.454e-03, Remain time: 4.8 min\n","Epoch 890/1300, Training Loss: 1.122e-03, Remain time: 4.9 min\n","Epoch 900/1300, Training Loss: 1.240e-03, Remain time: 4.7 min\n","Epoch 910/1300, Training Loss: 1.182e-03, Remain time: 5.1 min\n","Epoch 920/1300, Training Loss: 5.394e-04, Remain time: 4.6 min\n","Epoch 930/1300, Training Loss: 8.642e-04, Remain time: 6.1 min\n","Epoch 940/1300, Training Loss: 6.065e-04, Remain time: 4.2 min\n","Epoch 950/1300, Training Loss: 9.760e-04, Remain time: 6.0 min\n","Epoch 960/1300, Training Loss: 8.093e-04, Remain time: 4.2 min\n","  Model saved , Validation Loss: 7.664e-04, lr: 3.892e-05\n","  Model saved , Validation Loss: 7.649e-04, lr: 3.481e-05\n","Epoch 970/1300, Training Loss: 7.555e-04, Remain time: 3.9 min\n","Epoch 980/1300, Training Loss: 5.079e-04, Remain time: 3.8 min\n","  Model saved , Validation Loss: 7.592e-04, lr: 1.105e-05\n","  Model saved , Validation Loss: 7.462e-04, lr: 8.861e-06\n","Epoch 990/1300, Training Loss: 1.210e-03, Remain time: 3.6 min\n","  Model saved , Validation Loss: 7.279e-04, lr: 1.510e-06\n","  Model saved , Validation Loss: 7.213e-04, lr: 3.084e-08\n","Epoch 1000/1300, Training Loss: 7.168e-04, Remain time: 3.5 min\n","  Model saved , Validation Loss: 7.087e-04, lr: 3.084e-08\n","Epoch 1010/1300, Training Loss: 8.032e-04, Remain time: 3.5 min\n","Epoch 1020/1300, Training Loss: 7.219e-04, Remain time: 4.3 min\n","Epoch 1030/1300, Training Loss: 7.372e-04, Remain time: 3.2 min\n","Epoch 1040/1300, Training Loss: 6.929e-04, Remain time: 4.5 min\n","Epoch 1050/1300, Training Loss: 8.941e-04, Remain time: 2.9 min\n","Epoch 1060/1300, Training Loss: 8.999e-04, Remain time: 4.1 min\n","Epoch 1070/1300, Training Loss: 1.208e-03, Remain time: 3.2 min\n","Epoch 1080/1300, Training Loss: 1.432e-03, Remain time: 2.7 min\n","Epoch 1090/1300, Training Loss: 6.450e-04, Remain time: 2.5 min\n","Epoch 1100/1300, Training Loss: 1.429e-03, Remain time: 2.5 min\n","Epoch 1110/1300, Training Loss: 9.798e-04, Remain time: 2.3 min\n","Epoch 1120/1300, Training Loss: 1.027e-03, Remain time: 2.2 min\n","Epoch 1130/1300, Training Loss: 2.900e-03, Remain time: 2.8 min\n","Epoch 1140/1300, Training Loss: 8.116e-04, Remain time: 1.9 min\n","Epoch 1150/1300, Training Loss: 1.902e-02, Remain time: 2.5 min\n","Epoch 1160/1300, Training Loss: 9.206e-04, Remain time: 1.7 min\n","Epoch 1170/1300, Training Loss: 5.944e-04, Remain time: 1.6 min\n","Epoch 1180/1300, Training Loss: 1.277e-03, Remain time: 1.4 min\n","Epoch 1190/1300, Training Loss: 3.526e-03, Remain time: 1.3 min\n","Epoch 1200/1300, Training Loss: 1.975e-03, Remain time: 1.3 min\n","Epoch 1210/1300, Training Loss: 2.109e-03, Remain time: 1.1 min\n","Epoch 1220/1300, Training Loss: 1.468e-03, Remain time: 1.4 min\n","Epoch 1230/1300, Training Loss: 6.626e-03, Remain time: 0.9 min\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-00c1fc390eaa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"forward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#train_model(epoch_num=700,lr=2e-5,method=\"forward\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-30393ab0639b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epoch_num, lr, method)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Compute validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    182\u001b[0m             )\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             adamw(\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0mexp_avg_sq_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_max_exp_avg_sqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                 \u001b[0mexp_avg_sq_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_exp_avg_sqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_div_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train_model(epoch_num=1300,lr=5e-4,method=\"forward\")\n","#train_model(epoch_num=700,lr=2e-5,method=\"forward\")"]},{"cell_type":"markdown","metadata":{"id":"Cszxdb72g9AO"},"source":["## GPU monitor\n","### nvidia-smi -l 3"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}