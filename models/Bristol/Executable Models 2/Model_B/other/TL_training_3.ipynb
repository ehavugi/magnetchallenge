{"cells":[{"cell_type":"markdown","metadata":{"id":"XQSzNovNpM1J"},"source":["# User Colab Path Setting"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1703085358271,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"BY47VVFEpe5q"},"outputs":[],"source":["colab_dir = '/content/drive/MyDrive/DeepLearning/Challange_comb_shift_flip/MagNet_comb_modelB_cycle'  # example for colab\n","\n","platform = 'auto' # auto detect platform (colab, windows_local, linux_local, unknown)\n","#platform = 'colab'\n","#platform = 'windows_local'\n","#platform = 'linux_local'\n","#platform = 'unknown'"]},{"cell_type":"markdown","metadata":{"id":"EN1rAR3ADcfK"},"source":["# Trainnig process"]},{"cell_type":"markdown","metadata":{"id":"Ey9byKn_DcfK"},"source":["### Defult path config"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1703085358271,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"F5fy2h1NDcfK"},"outputs":[],"source":["model_saved_name=\"model_tl.ckpt\"\n","dataset_path=\"data/tl_dataset\""]},{"cell_type":"markdown","metadata":{"id":"F3jSpmi4pU5n"},"source":["### Path config"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21187,"status":"ok","timestamp":1703085379454,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"7EAuEhFiocKq","outputId":"48c43cef-2b5b-4343-a9c8-88349d2edd9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","\n","current execution path:  /content/drive/MyDrive/DeepLearning/Challange_comb_shift_flip/MagNet_comb_modelB_cycle\n","\n","current platform:  colab\n"]}],"source":["import os\n","\n","try:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","except ImportError:\n","    if os.path.exists('c:/'):  # check if it is windows\n","        platform = 'windows_local'\n","    elif os.path.exists('/home/'):  # check if it is linux\n","        platform = 'linux_local'\n","    else:\n","        platform = 'unknown'\n","else:\n","    platform = 'colab'\n","\n","if platform == 'colab':\n","  os.chdir(colab_dir)\n","\n","print('\\ncurrent execution path: ', os.getcwd())  #获取当前工作目录路径\n","print('\\ncurrent platform: ', platform)  #获取当前工作目录路径"]},{"cell_type":"markdown","metadata":{"id":"CHDhat43ogMQ"},"source":["## Cuda check"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5042,"status":"ok","timestamp":1703085384490,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"7Aipe8RLOzQk","outputId":"f3e4e942-bca0-4e69-89be-766cc7c3d7bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda good!\n","GPU num:  1\n","GPU type:  Tesla V100-SXM2-16GB\n","GPU memory: 16.94 Gbyte\n"]}],"source":["import torch\n","\n","gpu_num = 0\n","cuda_ready = False\n","\n","if torch.cuda.is_available():\n","    cuda_ready = True\n","    print('cuda good!')\n","    gpu_num = torch.cuda.device_count()\n","    if (gpu_num \u003c 1):\n","        print('GPU unavailable')\n","    else:\n","        print('GPU num: ', gpu_num)  # 查看GPU数量\n","        for gpu in range(gpu_num):\n","            print('GPU type: ', torch.cuda.get_device_name(gpu))  # 查看GPU名称\n","            print('GPU memory: {:.2f} Gbyte'.format(\n","                torch.cuda.get_device_properties(gpu).total_memory /\n","                1e9))  # 查看GPU总内存\n","else:\n","    cuda_ready = False\n","    print('cuda unavailable!')\n"]},{"cell_type":"markdown","metadata":{"id":"9z1whOUtaPbq"},"source":["## Start coding"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1703085384490,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"LSndganfafmO","outputId":"8b05d34d-2b6f-47a0-eb12-1c4594e734cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["colab\n","/content/drive/MyDrive/DeepLearning/Challange_comb_shift_flip/MagNet_comb_modelB_cycle\n","True\n","/content/drive/MyDrive/DeepLearning/Challange_comb_shift_flip/MagNet_comb_modelB_cycle\n"]}],"source":["print(platform)\n","print(os.getcwd())\n","print(cuda_ready)\n","print(os.path.abspath(''))"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":827,"status":"ok","timestamp":1703085385313,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"8q3WkMaUtvSZ"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","\n","\n","import NW_LSTM\n","import NN_DataLoader"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1703085385713,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"ftzXEac3tyHc","outputId":"2d741334-b8ff-497f-a387-7d06eadfd543"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device using  cuda\n","LSTMSeq2One(\n","  (lstm): LSTM(1, 30, num_layers=3, batch_first=True)\n","  (fc1): Linear(in_features=32, out_features=128, bias=True)\n","  (fc2): Linear(in_features=128, out_features=196, bias=True)\n","  (fc3): Linear(in_features=196, out_features=128, bias=True)\n","  (fc4): Linear(in_features=128, out_features=96, bias=True)\n","  (fc5): Linear(in_features=96, out_features=32, bias=True)\n","  (fc6): Linear(in_features=32, out_features=32, bias=True)\n","  (fc7): Linear(in_features=32, out_features=16, bias=True)\n","  (fc8): Linear(in_features=16, out_features=1, bias=True)\n","  (relu): ReLU()\n","  (leaky_relu): LeakyReLU(negative_slope=0.01)\n","  (elu): ELU(alpha=1.0)\n","  (sigmoid): Sigmoid()\n",")\n","Total number of parameters:  90653\n"]}],"source":["# Check if CUDA is available and if so, set the device to GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#device = torch.device(\"cpu\")\n","print(\"Device using \",device)\n","\n","# Instantiate the model with appropriate dimensions\n","model = model = NW_LSTM.get_global_model().to(device)\n","\n","# Print the model architecture and parameters number\n","print(model)\n","print(\"Total number of parameters: \", sum(p.numel() for p in model.parameters()))"]},{"cell_type":"markdown","metadata":{"id":"QKhTKu9cDcfN"},"source":["### Define training para"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703085385714,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"X6OqVZExt06B"},"outputs":[],"source":["def train_model(epoch_num=700,lr=2e-4,method=\"forward\"):\n","\n","    # Define the loss function and optimizer\n","    #loss_fn = nn.MSELoss()\n","    loss_fn = NW_LSTM.RelativeLoss()\n","    #loss_fn = NW_LSTM.RelativeLoss_abs()\n","    optimizer = optim.AdamW(model.parameters(), lr=lr)\n","\n","    # lr scheduler\n","    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=1, last_epoch=-1)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200, eta_min=0, last_epoch=-1)\n","\n","    # Default para in desktop env\n","    epochs = 10\n","    valid_batch_size=1000\n","\n","    if platform == \"colab\":\n","      epochs = epoch_num\n","      valid_batch_size=3000\n","\n","\n","    train_dataloader = NN_DataLoader.get_dataLoader(os.path.normpath(dataset_path +\n","                                                                \"/train.mat\"),\n","                                            batch_size=128)\n","\n","    # Get validation data\n","    valid_dataloader = NN_DataLoader.get_dataLoader(os.path.normpath(dataset_path +\n","                                                                \"/valid.mat\"),\n","                                                batch_size=valid_batch_size)\n","    valid_inputs, valid_targets = next(iter(valid_dataloader))\n","    valid_inputs, valid_targets = valid_inputs.to(device), valid_targets.to(device)\n","\n","    # Load the pre-train model if it exists\n","    try:\n","      model.load_state_dict(torch.load(model_saved_name))\n","      print(\"Pre-train model loaded\")\n","    except:\n","      print(\"No model found, start training from scratch\")\n","      pass\n","\n","\n","\n","    # estimate time used for training\n","    import time\n","    t0 = time.perf_counter()\n","\n","    # Save the model with the lowest validation loss\n","    with torch.no_grad():\n","        valid_outputs = model(valid_inputs)\n","        # Compute loss\n","        minium_loss = loss_fn(valid_outputs, valid_targets)\n","\n","    # Train the model\n","    for epoch in range(epochs):\n","\n","\n","        # estimate time used for one epoch(s)\n","        t_epoch = time.perf_counter() - t0\n","        t0 = time.perf_counter()\n","\n","        # Train one epoch\n","        for i, (train_inputs, train_targets) in enumerate(train_dataloader):\n","            # Move data to device\n","            train_inputs, train_targets = train_inputs.to(device), train_targets.to(device)\n","\n","            # Forward pass\n","            if method == \"forward\":\n","                train_outputs = model(train_inputs)\n","            elif method == \"valid\":\n","                train_outputs = model.valid(train_inputs)\n","\n","            # Compute loss\n","            loss = loss_fn(train_outputs, train_targets)\n","\n","            # Backward pass and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # Compute validation loss\n","        if epoch \u003e 0:\n","            with torch.no_grad():\n","                valid_outputs = model(valid_inputs)\n","                # Compute loss\n","                valid_loss = loss_fn(valid_outputs, valid_targets)\n","\n","            if valid_loss \u003c minium_loss:\n","                minium_loss = valid_loss\n","                torch.save(model.state_dict(), model_saved_name)\n","                print(f\"  Model saved , Validation Loss: {valid_loss.item():.3e}, lr: {optimizer.param_groups[0]['lr']:.3e}\")\n","\n","        # update lr\n","        scheduler.step()\n","\n","        # Print loss every 10 epochs\n","        if (epoch + 1) % 10 == 0:\n","            print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {loss.item():.3e}, \"\n","                #   f\"Validation Loss: {valid_loss.item():.3e} ,\"\n","                f\"Remain time: {t_epoch/60 * (epochs - epoch - 1):.1f} min\")\n"]},{"cell_type":"markdown","metadata":{"id":"JVWF5osJDcfN"},"source":["### Training loop"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1703085385714,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":0},"id":"HVfNZrtoottv"},"outputs":[],"source":["#train_model(epoch_num=10,lr=2e-4,method=\"forward\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"oGiB5uWYottv"},"outputs":[{"name":"stdout","output_type":"stream","text":["Pre-train model loaded\n","Epoch 10/120, Training Loss: 2.509e-03, Remain time: 2.0 min\n","Epoch 20/120, Training Loss: 1.122e-04, Remain time: 2.7 min\n","Epoch 30/120, Training Loss: 4.636e-04, Remain time: 2.2 min\n","Epoch 40/120, Training Loss: 3.693e-02, Remain time: 1.5 min\n","Epoch 50/120, Training Loss: 2.044e-04, Remain time: 1.3 min\n","Epoch 60/120, Training Loss: 3.224e-04, Remain time: 1.1 min\n","Epoch 70/120, Training Loss: 2.441e-04, Remain time: 1.0 min\n","Epoch 80/120, Training Loss: 1.052e-03, Remain time: 0.9 min\n","Epoch 90/120, Training Loss: 3.143e-04, Remain time: 0.8 min\n","Epoch 100/120, Training Loss: 1.925e-04, Remain time: 0.4 min\n","Epoch 110/120, Training Loss: 3.461e-04, Remain time: 0.2 min\n","Epoch 120/120, Training Loss: 8.511e-05, Remain time: 0.0 min\n","Pre-train model loaded\n","  Model saved , Validation Loss: 2.199e-04, lr: 2.000e-05\n","Epoch 10/280, Training Loss: 1.185e-04, Remain time: 5.0 min\n","Epoch 20/280, Training Loss: 1.209e-04, Remain time: 4.9 min\n","Epoch 30/280, Training Loss: 9.441e-05, Remain time: 6.7 min\n","  Model saved , Validation Loss: 2.197e-04, lr: 1.891e-05\n","Epoch 40/280, Training Loss: 1.156e-04, Remain time: 6.1 min\n","Epoch 50/280, Training Loss: 1.138e-04, Remain time: 4.3 min\n","Epoch 60/280, Training Loss: 1.343e-04, Remain time: 4.1 min\n","Epoch 70/280, Training Loss: 2.736e-04, Remain time: 3.9 min\n","Epoch 80/280, Training Loss: 2.900e-04, Remain time: 3.7 min\n","Epoch 90/280, Training Loss: 1.258e-04, Remain time: 5.0 min\n","Epoch 100/280, Training Loss: 1.404e-04, Remain time: 4.7 min\n","  Model saved , Validation Loss: 2.158e-04, lr: 9.215e-06\n","Epoch 110/280, Training Loss: 7.689e-05, Remain time: 3.3 min\n","Epoch 120/280, Training Loss: 1.686e-04, Remain time: 3.0 min\n","Epoch 130/280, Training Loss: 7.008e-05, Remain time: 2.8 min\n","  Model saved , Validation Loss: 2.150e-04, lr: 4.510e-06\n","Epoch 140/280, Training Loss: 9.807e-05, Remain time: 2.7 min\n","Epoch 150/280, Training Loss: 1.912e-04, Remain time: 2.9 min\n","Epoch 160/280, Training Loss: 2.129e-04, Remain time: 3.2 min\n","Epoch 170/280, Training Loss: 1.386e-04, Remain time: 2.1 min\n","  Model saved , Validation Loss: 2.148e-04, lr: 7.022e-07\n","Epoch 180/280, Training Loss: 1.578e-04, Remain time: 1.9 min\n","  Model saved , Validation Loss: 2.118e-04, lr: 4.421e-07\n","Epoch 190/280, Training Loss: 8.025e-05, Remain time: 1.7 min\n","Epoch 200/280, Training Loss: 1.338e-04, Remain time: 2.2 min\n","Epoch 210/280, Training Loss: 1.455e-04, Remain time: 1.5 min\n","Epoch 220/280, Training Loss: 1.225e-04, Remain time: 1.6 min\n","Epoch 230/280, Training Loss: 1.685e-04, Remain time: 1.0 min\n","Epoch 240/280, Training Loss: 1.334e-04, Remain time: 0.8 min\n","  Model saved , Validation Loss: 2.107e-04, lr: 2.604e-06\n","Epoch 250/280, Training Loss: 1.150e-04, Remain time: 0.6 min\n","  Model saved , Validation Loss: 2.039e-04, lr: 3.387e-06\n","Epoch 260/280, Training Loss: 1.161e-04, Remain time: 0.4 min\n","Epoch 270/280, Training Loss: 9.851e-05, Remain time: 0.2 min\n","Epoch 280/280, Training Loss: 1.206e-04, Remain time: 0.0 min\n","Pre-train model loaded\n","Epoch 10/120, Training Loss: 2.604e-04, Remain time: 2.6 min\n","Epoch 20/120, Training Loss: 2.274e-04, Remain time: 1.8 min\n","Epoch 30/120, Training Loss: 1.619e-04, Remain time: 1.7 min\n","Epoch 40/120, Training Loss: 1.363e-04, Remain time: 1.5 min\n","Epoch 50/120, Training Loss: 3.659e-04, Remain time: 1.3 min\n","Epoch 60/120, Training Loss: 3.702e-04, Remain time: 1.7 min\n","Epoch 70/120, Training Loss: 1.182e-03, Remain time: 1.3 min\n","Epoch 80/120, Training Loss: 4.674e-04, Remain time: 0.7 min\n","Epoch 90/120, Training Loss: 1.924e-04, Remain time: 0.6 min\n","Epoch 100/120, Training Loss: 4.683e-04, Remain time: 0.4 min\n","Epoch 110/120, Training Loss: 1.483e-04, Remain time: 0.2 min\n","Epoch 120/120, Training Loss: 5.702e-04, Remain time: 0.0 min\n","Pre-train model loaded\n","  Model saved , Validation Loss: 2.274e-04, lr: 2.000e-05\n","Epoch 10/280, Training Loss: 2.601e-04, Remain time: 7.0 min\n","  Model saved , Validation Loss: 2.269e-04, lr: 1.965e-05\n","Epoch 20/280, Training Loss: 1.307e-04, Remain time: 4.8 min\n","Epoch 30/280, Training Loss: 1.562e-04, Remain time: 4.8 min\n","  Model saved , Validation Loss: 2.253e-04, lr: 1.876e-05\n","  Model saved , Validation Loss: 2.239e-04, lr: 1.869e-05\n","  Model saved , Validation Loss: 2.199e-04, lr: 1.827e-05\n","Epoch 40/280, Training Loss: 8.695e-05, Remain time: 4.5 min\n","Epoch 50/280, Training Loss: 1.623e-04, Remain time: 4.4 min\n","Epoch 60/280, Training Loss: 9.735e-05, Remain time: 4.2 min\n","Epoch 70/280, Training Loss: 1.123e-04, Remain time: 5.8 min\n","Epoch 80/280, Training Loss: 2.640e-04, Remain time: 5.2 min\n","  Model saved , Validation Loss: 2.194e-04, lr: 1.294e-05\n","  Model saved , Validation Loss: 2.164e-04, lr: 1.203e-05\n","  Model saved , Validation Loss: 2.139e-04, lr: 1.172e-05\n","Epoch 90/280, Training Loss: 3.008e-04, Remain time: 3.7 min\n","Epoch 100/280, Training Loss: 1.527e-04, Remain time: 3.5 min\n","  Model saved , Validation Loss: 2.094e-04, lr: 9.686e-06\n","Epoch 110/280, Training Loss: 1.310e-04, Remain time: 3.3 min\n","Epoch 120/280, Training Loss: 1.016e-04, Remain time: 3.1 min\n","Epoch 130/280, Training Loss: 1.357e-04, Remain time: 2.9 min\n","Epoch 140/280, Training Loss: 7.413e-05, Remain time: 3.0 min\n","  Model saved , Validation Loss: 2.093e-04, lr: 3.387e-06\n","Epoch 150/280, Training Loss: 4.395e-05, Remain time: 3.3 min\n","Epoch 160/280, Training Loss: 1.570e-04, Remain time: 3.0 min\n","Epoch 170/280, Training Loss: 9.335e-05, Remain time: 2.1 min\n","  Model saved , Validation Loss: 2.072e-04, lr: 9.517e-07\n","Epoch 180/280, Training Loss: 2.711e-04, Remain time: 1.9 min\n","  Model saved , Validation Loss: 2.013e-04, lr: 1.489e-07\n","Epoch 190/280, Training Loss: 2.357e-04, Remain time: 1.7 min\n","Epoch 200/280, Training Loss: 9.863e-05, Remain time: 1.5 min\n","Epoch 210/280, Training Loss: 1.044e-04, Remain time: 1.3 min\n","Epoch 220/280, Training Loss: 1.452e-04, Remain time: 1.1 min\n","  Model saved , Validation Loss: 1.987e-04, lr: 1.020e-06\n","Epoch 230/280, Training Loss: 2.191e-04, Remain time: 0.9 min\n","Epoch 240/280, Training Loss: 1.030e-04, Remain time: 1.1 min\n","Epoch 250/280, Training Loss: 1.138e-04, Remain time: 0.8 min\n","Epoch 260/280, Training Loss: 7.217e-05, Remain time: 0.4 min\n","Epoch 270/280, Training Loss: 8.217e-05, Remain time: 0.2 min\n","Epoch 280/280, Training Loss: 7.244e-05, Remain time: 0.0 min\n","Pre-train model loaded\n","Epoch 10/120, Training Loss: 3.007e-04, Remain time: 2.1 min\n","Epoch 20/120, Training Loss: 2.426e-04, Remain time: 1.9 min\n","Epoch 30/120, Training Loss: 6.402e-04, Remain time: 1.7 min\n","Epoch 40/120, Training Loss: 3.779e-04, Remain time: 1.5 min\n","Epoch 50/120, Training Loss: 1.967e-04, Remain time: 1.3 min\n","Epoch 60/120, Training Loss: 2.218e-02, Remain time: 1.3 min\n","Epoch 70/120, Training Loss: 2.688e-04, Remain time: 1.3 min\n","Epoch 80/120, Training Loss: 1.395e-04, Remain time: 1.0 min\n","Epoch 90/120, Training Loss: 1.099e-04, Remain time: 0.6 min\n","Epoch 100/120, Training Loss: 1.308e-04, Remain time: 0.4 min\n","Epoch 110/120, Training Loss: 2.478e-04, Remain time: 0.2 min\n","Epoch 120/120, Training Loss: 1.692e-04, Remain time: 0.0 min\n","Pre-train model loaded\n","  Model saved , Validation Loss: 2.189e-04, lr: 2.000e-05\n","Epoch 10/280, Training Loss: 2.036e-04, Remain time: 4.9 min\n","Epoch 20/280, Training Loss: 2.586e-04, Remain time: 4.7 min\n","Epoch 30/280, Training Loss: 1.550e-04, Remain time: 6.3 min\n","  Model saved , Validation Loss: 2.183e-04, lr: 1.891e-05\n","Epoch 40/280, Training Loss: 1.337e-04, Remain time: 4.4 min\n","Epoch 50/280, Training Loss: 2.493e-04, Remain time: 4.2 min\n","Epoch 60/280, Training Loss: 1.683e-04, Remain time: 4.0 min\n","Epoch 70/280, Training Loss: 1.476e-04, Remain time: 3.8 min\n","  Model saved , Validation Loss: 2.164e-04, lr: 1.426e-05\n","Epoch 80/280, Training Loss: 1.400e-04, Remain time: 3.7 min\n","Epoch 90/280, Training Loss: 2.450e-04, Remain time: 3.4 min\n","Epoch 100/280, Training Loss: 2.534e-04, Remain time: 4.6 min\n","Epoch 110/280, Training Loss: 1.150e-04, Remain time: 3.4 min\n","  Model saved , Validation Loss: 2.088e-04, lr: 7.819e-06\n","Epoch 120/280, Training Loss: 2.342e-04, Remain time: 2.8 min\n","Epoch 130/280, Training Loss: 1.450e-04, Remain time: 2.7 min\n","Epoch 140/280, Training Loss: 1.488e-04, Remain time: 2.5 min\n","Epoch 150/280, Training Loss: 1.960e-04, Remain time: 2.3 min\n","  Model saved , Validation Loss: 2.071e-04, lr: 2.710e-06\n","  Model saved , Validation Loss: 2.061e-04, lr: 2.196e-06\n","Epoch 160/280, Training Loss: 1.870e-04, Remain time: 2.2 min\n","Epoch 170/280, Training Loss: 2.594e-04, Remain time: 2.8 min\n","Epoch 180/280, Training Loss: 1.425e-04, Remain time: 2.3 min\n","Epoch 190/280, Training Loss: 1.017e-04, Remain time: 1.7 min\n","Epoch 200/280, Training Loss: 1.562e-04, Remain time: 1.4 min\n","Epoch 210/280, Training Loss: 1.873e-04, Remain time: 1.3 min\n","Epoch 220/280, Training Loss: 9.873e-05, Remain time: 1.1 min\n","  Model saved , Validation Loss: 2.041e-04, lr: 4.894e-07\n","Epoch 230/280, Training Loss: 1.606e-04, Remain time: 0.9 min\n","Epoch 240/280, Training Loss: 9.769e-05, Remain time: 0.9 min\n","Epoch 250/280, Training Loss: 2.245e-04, Remain time: 0.8 min\n","Epoch 260/280, Training Loss: 8.736e-05, Remain time: 0.4 min\n","Epoch 270/280, Training Loss: 9.793e-05, Remain time: 0.2 min\n","Epoch 280/280, Training Loss: 3.120e-04, Remain time: 0.0 min\n","Pre-train model loaded\n","Epoch 10/120, Training Loss: 5.623e-04, Remain time: 1.9 min\n","Epoch 20/120, Training Loss: 2.513e-03, Remain time: 1.8 min\n","Epoch 30/120, Training Loss: 2.311e-03, Remain time: 1.7 min\n","Epoch 40/120, Training Loss: 4.723e-04, Remain time: 2.1 min\n","Epoch 50/120, Training Loss: 1.028e-04, Remain time: 1.4 min\n","Epoch 60/120, Training Loss: 2.650e-04, Remain time: 1.1 min\n","Epoch 70/120, Training Loss: 3.225e-04, Remain time: 0.9 min\n","Epoch 80/120, Training Loss: 2.609e-04, Remain time: 0.7 min\n","Epoch 90/120, Training Loss: 1.523e-03, Remain time: 0.5 min\n","Epoch 100/120, Training Loss: 1.799e-04, Remain time: 0.4 min\n","Epoch 110/120, Training Loss: 2.363e-04, Remain time: 0.2 min\n","Epoch 120/120, Training Loss: 1.409e-04, Remain time: 0.0 min\n","Pre-train model loaded\n","  Model saved , Validation Loss: 2.037e-04, lr: 2.000e-05\n","Epoch 10/280, Training Loss: 1.911e-04, Remain time: 4.9 min\n","Epoch 20/280, Training Loss: 1.304e-04, Remain time: 4.8 min\n","Epoch 30/280, Training Loss: 7.592e-05, Remain time: 4.6 min\n","Epoch 40/280, Training Loss: 1.327e-04, Remain time: 4.2 min\n","Epoch 50/280, Training Loss: 2.473e-04, Remain time: 4.0 min\n","Epoch 60/280, Training Loss: 1.207e-04, Remain time: 4.1 min\n","Epoch 70/280, Training Loss: 1.943e-04, Remain time: 4.1 min\n","Epoch 80/280, Training Loss: 1.588e-04, Remain time: 5.2 min\n","Epoch 90/280, Training Loss: 1.255e-04, Remain time: 3.4 min\n","Epoch 100/280, Training Loss: 8.425e-05, Remain time: 3.3 min\n","Epoch 110/280, Training Loss: 8.301e-05, Remain time: 3.1 min\n","Epoch 120/280, Training Loss: 2.167e-04, Remain time: 2.9 min\n","Epoch 130/280, Training Loss: 1.484e-04, Remain time: 2.7 min\n","Epoch 140/280, Training Loss: 2.225e-04, Remain time: 2.9 min\n","Epoch 150/280, Training Loss: 3.675e-04, Remain time: 3.4 min\n","Epoch 160/280, Training Loss: 6.546e-05, Remain time: 2.0 min\n","Epoch 170/280, Training Loss: 1.578e-04, Remain time: 1.9 min\n","Epoch 180/280, Training Loss: 1.094e-04, Remain time: 1.8 min\n","Epoch 190/280, Training Loss: 2.537e-04, Remain time: 1.6 min\n","  Model saved , Validation Loss: 1.987e-04, lr: 4.438e-08\n","Epoch 200/280, Training Loss: 1.989e-04, Remain time: 1.5 min\n","Epoch 210/280, Training Loss: 1.089e-04, Remain time: 1.6 min\n","Epoch 220/280, Training Loss: 1.060e-04, Remain time: 1.5 min\n","Epoch 230/280, Training Loss: 1.836e-04, Remain time: 0.9 min\n","Epoch 240/280, Training Loss: 2.194e-04, Remain time: 0.7 min\n","Epoch 250/280, Training Loss: 2.054e-04, Remain time: 0.5 min\n","Epoch 260/280, Training Loss: 3.599e-04, Remain time: 0.3 min\n","Epoch 270/280, Training Loss: 8.239e-05, Remain time: 0.2 min\n","Epoch 280/280, Training Loss: 1.784e-04, Remain time: 0.0 min\n","Pre-train model loaded\n","Epoch 10/120, Training Loss: 1.082e-04, Remain time: 2.8 min\n","Epoch 20/120, Training Loss: 2.036e-03, Remain time: 1.8 min\n","Epoch 30/120, Training Loss: 2.093e-04, Remain time: 1.6 min\n","Epoch 40/120, Training Loss: 1.129e-04, Remain time: 1.4 min\n","Epoch 50/120, Training Loss: 5.820e-03, Remain time: 1.3 min\n","Epoch 60/120, Training Loss: 4.125e-04, Remain time: 1.1 min\n","Epoch 70/120, Training Loss: 1.804e-04, Remain time: 1.3 min\n","Epoch 80/120, Training Loss: 1.447e-04, Remain time: 1.0 min\n","Epoch 90/120, Training Loss: 7.384e-04, Remain time: 0.5 min\n","Epoch 100/120, Training Loss: 5.616e-04, Remain time: 0.4 min\n","Epoch 110/120, Training Loss: 1.806e-04, Remain time: 0.2 min\n","Epoch 120/120, Training Loss: 1.121e-04, Remain time: 0.0 min\n","Pre-train model loaded\n","Epoch 10/280, Training Loss: 1.327e-04, Remain time: 4.8 min\n","Epoch 20/280, Training Loss: 1.410e-04, Remain time: 6.4 min\n","Epoch 30/280, Training Loss: 1.374e-04, Remain time: 6.1 min\n","Epoch 40/280, Training Loss: 1.500e-04, Remain time: 4.2 min\n","Epoch 50/280, Training Loss: 2.660e-04, Remain time: 4.1 min\n","  Model saved , Validation Loss: 2.203e-04, lr: 1.637e-05\n","Epoch 60/280, Training Loss: 1.978e-04, Remain time: 3.9 min\n","  Model saved , Validation Loss: 2.111e-04, lr: 1.509e-05\n","Epoch 70/280, Training Loss: 8.825e-05, Remain time: 3.8 min\n","Epoch 80/280, Training Loss: 1.080e-04, Remain time: 3.4 min\n","Epoch 90/280, Training Loss: 1.870e-04, Remain time: 4.9 min\n","Epoch 100/280, Training Loss: 1.893e-04, Remain time: 3.7 min\n","  Model saved , Validation Loss: 2.064e-04, lr: 9.686e-06\n","Epoch 110/280, Training Loss: 1.439e-04, Remain time: 3.0 min\n","Epoch 120/280, Training Loss: 1.327e-04, Remain time: 2.8 min\n","Epoch 130/280, Training Loss: 1.352e-04, Remain time: 2.7 min\n","Epoch 140/280, Training Loss: 2.975e-04, Remain time: 2.5 min\n","Epoch 150/280, Training Loss: 7.486e-05, Remain time: 2.3 min\n","  Model saved , Validation Loss: 2.063e-04, lr: 2.929e-06\n","  Model saved , Validation Loss: 2.056e-04, lr: 2.819e-06\n","Epoch 160/280, Training Loss: 1.345e-04, Remain time: 3.0 min\n","Epoch 170/280, Training Loss: 1.567e-04, Remain time: 2.3 min\n","Epoch 180/280, Training Loss: 2.695e-04, Remain time: 1.8 min\n","  Model saved , Validation Loss: 1.979e-04, lr: 1.489e-07\n","Epoch 190/280, Training Loss: 8.935e-05, Remain time: 1.6 min\n","Epoch 200/280, Training Loss: 1.068e-04, Remain time: 1.4 min\n","Epoch 210/280, Training Loss: 1.040e-04, Remain time: 1.2 min\n","Epoch 220/280, Training Loss: 1.079e-04, Remain time: 1.5 min\n","Epoch 230/280, Training Loss: 8.016e-05, Remain time: 1.2 min\n","Epoch 240/280, Training Loss: 3.019e-04, Remain time: 0.7 min\n","Epoch 250/280, Training Loss: 7.862e-05, Remain time: 0.5 min\n","Epoch 260/280, Training Loss: 2.179e-04, Remain time: 0.4 min\n","Epoch 270/280, Training Loss: 1.397e-04, Remain time: 0.2 min\n","Epoch 280/280, Training Loss: 1.740e-04, Remain time: 0.0 min\n"]}],"source":["for i in range(5):\n","  train_model(epoch_num=120,lr=2e-4,method=\"forward\")\n","  train_model(epoch_num=280,lr=2e-5,method=\"forward\")"]},{"cell_type":"markdown","metadata":{"id":"Cszxdb72g9AO"},"source":["## GPU monitor\n","### nvidia-smi -l 3"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}